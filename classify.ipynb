{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"\")\n",
    "\n",
    "if \"t_sec\" in df.columns:\n",
    "    df = df.drop(columns=[\"t_sec\"])\n",
    "\n",
    "df_back = df.drop(columns=['ANeck_x', 'ANeck_y', 'ANeck_z', 'GNeck_x', 'GNeck_y', 'GNeck_z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):   \n",
    "    '''\n",
    "    Splits training data into trainings and test data.\n",
    "\n",
    "    Parameters:\n",
    "        data (DataFrame): Any Data Frame.\n",
    "    \n",
    "    Returns:\n",
    "        x_train (DataFrame): Features for traning a model.\n",
    "        y_train (Series): Targets for training a model.\n",
    "        x_test (DataFrame): Features for testing a trained model.\n",
    "        y_test (Series): Targets for testing a trained model.\n",
    "    '''\n",
    "\n",
    "    x = data.drop([\"Behavior\"], axis=1)\n",
    "    y = data[\"Behavior\"]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test = split_data(df_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlations(values):       \n",
    "    '''\n",
    "    Plots a heatmap which visualizes the correlations between different DF columns.\n",
    "\n",
    "    Parameters:\n",
    "        values (DataFrame): Any Data Frame with multiple columns.       \n",
    "    '''\n",
    "    sns.set(rc={'figure.figsize':(12,8)})\n",
    "    sns.heatmap(values.corr().abs(),annot=True)\n",
    "\n",
    "\n",
    "plot_correlations(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_algo(x, y):   \n",
    "    '''\n",
    "    Tests different classifier alogrithmns on a classification task to choose the most appropriate one for optimization.\n",
    "    Visualizes the test results as a boxplot.\n",
    "\n",
    "    Parameters:\n",
    "        x (DataFrame): Features for traning a model.\n",
    "        y (Series): Targets for training a model.\n",
    "    '''\n",
    "\n",
    "    algs = [(\"GBC\", GradientBoostingClassifier()),\n",
    "            (\"GNB\", GaussianNB()),\n",
    "            (\"KNN\", KNeighborsClassifier()),\n",
    "            (\"LDA\", LinearDiscriminantAnalysis()),\n",
    "            (\"RFC\", RandomForestClassifier()),\n",
    "            (\"SVC\", SVC()),\n",
    "            (\"TREE\", DecisionTreeClassifier())]\n",
    "\n",
    "    results = []\n",
    "    names = []\n",
    "\n",
    "    for name, model in algs:\n",
    "        cv_results = cross_val_score(model, x, y, n_jobs=3, verbose=1)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "\n",
    "    plt.boxplot(results, labels=names)\n",
    "    plt.title(\"Classifier Comparison\")\n",
    "    plt.xlabel(\"Classifier\")\n",
    "    plt.ylabel(\"cross-validation-score\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#compare_algo(x_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(x, y):\n",
    "    '''\n",
    "    Performs a grid search to choose the best possible parameters.\n",
    "\n",
    "    Parameters:\n",
    "        x (DataFrame): Features for traning a model.\n",
    "        y (Series): Targets for training a model.\n",
    "\n",
    "    Returns:\n",
    "        best_model (estimator): Estimator which got the best results.\n",
    "    '''\n",
    "\n",
    "    model = RandomForestClassifier(warm_start=True)\n",
    "    params = {\n",
    "        \"n_estimators\": [10, 50, 100, 500, 1000],\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "        \"bootstrap\": [True, False]\n",
    "    }\n",
    "    search_model = GridSearchCV(estimator=model, param_grid=params, n_jobs=3, verbose=2)\n",
    "    search_model.fit(x, y)\n",
    "    best_model = search_model.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "\n",
    "#best_model = tune_model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(model):\n",
    "    '''\n",
    "    Reads the relevance of the various features and visualizes these values.\n",
    "\n",
    "    Parameters:\n",
    "        model (estimator): Trained classifier estimator.\n",
    "    '''\n",
    "\n",
    "    imp = model.feature_importances_ \n",
    "    features = x_train.columns \n",
    "    indices = np.argsort(imp)\n",
    "    \n",
    "    plt.title('Feature Importance\\n', fontsize = 15)\n",
    "    plt.ylabel(\"Feature\\n\")\n",
    "    plt.xlabel(\"\\nImportance\")\n",
    "    plt.barh(range(len(indices)), imp[indices], align='center')\n",
    "    plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_matrix(test, pred):\n",
    "    '''\n",
    "    Visualizes a confusion matrix based on the test data split and a predicition of an classifier model.\n",
    "\n",
    "    Parameters:\n",
    "        test (Series): Targets for testing a trained model.\n",
    "        pred (array): Predicted classes from a classifier model.\n",
    "    '''\n",
    "    \n",
    "    labels = test.unique()\n",
    "    conf_matrix = confusion_matrix(test, pred)\n",
    "\n",
    "    sns.heatmap(conf_matrix, xticklabels=labels, yticklabels=labels, annot=True,linewidths = 0.1, fmt=\"d\", cmap = \"YlGnBu\")\n",
    "    sns.set(rc={'figure.figsize':(20,16)})\n",
    "    plt.title(\"Confusion matrix\\n\", fontsize = 20)\n",
    "    plt.ylabel(\"True label\\n\")\n",
    "    plt.xlabel(\"\\nPred label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    '''\n",
    "    Tests a ML-model and outputs different metrics.\n",
    "\n",
    "    Parameters:\n",
    "        model (estimator): Trained classifier estimator.\n",
    "    '''\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(\"\\n -----------------Classification Report-----------------\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"\\n -------------------Confusion Matrix--------------------\\n\")\n",
    "    plot_conf_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n ------------------Feature Importance-------------------\\n\")\n",
    "    feature_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfclf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion=\"gini\",\n",
    "    max_features=\"sqrt\",\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    bootstrap=False,\n",
    "    n_jobs=3)\n",
    "\n",
    "rfclf.fit(x_train, y_train)\n",
    "\n",
    "test_model(rfclf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cffa35e1638e1c79492d83b35465f30c828cbf3d6da9ee4a594aeef5efaf2bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
